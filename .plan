--- idea ---
measure performance of anti-entropy methods

--- what performance is ---
bandwidth (straightforward to reconcile simulation vs. real-world)
time (difficult to reconcile simulation vs. real-world)
robustness during network instability (qualitative, but worth looking at)

--- what to measure ---
base case - pairwise comparison of all data
one level of hashing (one top level hash, then base case)
additional levels?
full merkle tree
variation: non-binary merkle tree
optimizations on top of the above (lazy vs eager hash computation, sending trees one level at a time, etc.)

--- elaboration ---
given:
i data items stored on two replicas
c conflicts between the two replicas
determine:
how well do the various anti-entropy methods perform?
for example, the naive method is the best above some number of conflicts whereas methods with a top-level hash perform the best with a low number of conflicts (high probability of replicas being perfectly synchronized).
results can be presented in a line graph of the number of conflicts vs performance, with one line per synchronization method.

--- extensions ---
datum size vs. hash size
replace conflict count with simulation of writes with chance of nonpropagation

--- to do ---
graph results
poster rough draft
implement partial merkle trees (only one level, or only x levels)
implement nonbinary merkle trees
qualitatively evaluate robustness of methods
consider measuring time
run benchmarks with large sample size